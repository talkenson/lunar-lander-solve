# TNN//null solve of LunarLander-v2 
(Gym, OpenAI, MTS Contest - NTI)
 
 

### Промежуточные результаты
Ниже, по ссылке, представлена видео-демонстрация нашего решения задачи LunarLander-v2:
> Вот ссылочка: https://youtu.be/pzyWrRXvYT0
 
 


### Gists с результатами обучения и теста
> Обращаем Ваше внимание на то, что при дообучении агента была совершено 100 эпизодов, которые заполняли память по весам, снятым с агента, ученого на ~2000 эпизодов (2000 +- 300).
 
 


#### Сами гисты
- https://gist.github.com/tnnNull/1095b56a6291971ad70a5c0923a4555c
- https://gist.github.com/tnnNull/60b9b4f436ecc2a7ddab1901edd293f6

## Описание
### Часть первая, или как интересно мы начали понимать о чем идет речь на второй день
 
Была оформлена модель, содержащая в себе 2 скрытых слоя, 64 нейрона на каждую с функцией активации RELU
Входной слой принимал массив из observation, выходной слой на softmax, с размером action

### Часть вторая, или почему я больше не люблю обучение с подкреплением
 
Был написан массив, содержащий историю действий, представленных в виде 
> [s, a, r, s1], 
> где s - текущий state, a - совершенное действие, r - полученный reward, s1 - новое состояние, после выполнения a.

После чего мы тренировали агента около 2000 эпизодов.

### Часть третья, и ее мы дополним позже

## Полные результаты
> Вот ссылочка: https://youtu.be/oDuOOPdJ4Jw

